{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation de l'environnement\n",
    "\n",
    "Ci-dessous quelques imports et précautions préalables à notre travail. Il n'est pas inutile de les parcourir.\n",
    "Si nécessaire créer un bloc au démarrage pour installer toutes les librairies nécessaires en exécutant chacune leur tour les commandes suivantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from statistics import mean\n",
    "from time import *\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "\n",
    "# stabilité du notebook d'une exécution à l'autre\n",
    "random=np.random.default_rng(42) \n",
    "\n",
    "# jolies figures directement dans le notebook\n",
    "%matplotlib inline\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des dataframes\n",
    "\n",
    "Nous commençons par importer les CSV afin de crée les dataframes correspondant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fileName):\n",
    "    csv_path = os.path.join('../data', fileName)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_survey_data = load_data('employee_survey_data.csv')\n",
    "manager_survey_data = load_data('manager_survey_data.csv')\n",
    "in_time = load_data('in_time.csv')\n",
    "out_time = load_data('out_time.csv')\n",
    "general_data = load_data('general_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choix des données\n",
    "\n",
    "## Éthique\n",
    "\n",
    "Dans le cas de notre modèle et de l'utilisation de nos données il est important de déterminer étiquement la conservation de certaines données ou non. \n",
    "\n",
    "Pour cela nous avons procédé à un brainstorming et à une lecture des recommendations de la CNIL pour conserver uniquement les données nécessaires et ne prétant pas à une possible discrimination.\n",
    "\n",
    "Voici la liste des données que nous ne souhaitons pas conserver pour notre modèle :\n",
    "\n",
    "- **L’âge des employés (Age) :** Nous souhaitons rester dans la plus grande neutralité possible.Effectivement, l’âge ne doit pas nous permettre de définir si une personne est plus à même de quitter l’entreprise ou non. \n",
    "<br>\n",
    "\n",
    "- **Le genre des employés (Gender) :** Le genre est une donnée non pertinante sur les critères qui pousserai à un turnover. Cette donnée pourrait être discrimante \n",
    "<br>\n",
    "\n",
    "- **Le statut marital (MaritalStatus) :** Cette donnée ne nous permetrai pas d’interpreter des critères cohérent concernant les Turn-over dans l’entrprise. Ce serai une surinterpretation des données fournis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the columns for ethic\n",
    "general_dataset = general_data.copy() #copy the dataframe to avoid changing the original one\n",
    "general_dataset.drop(\"Age\", axis=1, inplace=True) \n",
    "general_dataset.drop(\"Gender\", axis=1, inplace=True)\n",
    "general_dataset.drop(\"MaritalStatus\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logique\n",
    "\n",
    "Il est également nécessaire de déterminer d'une manière logique les données utile à conserver ou non. \n",
    "\n",
    "Pour cela il suffit d'isoler dans un premier temps les colonnes de la table ***General_data***  ou le champs de valeur est égal à 1, c'est à dire que chaque données est la même.\n",
    "\n",
    "Pour cela il suffit d'executer cette fonction afin de déterminer les champs répondant à cette condition :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in general_data.columns:\n",
    "    value = general_data[col].nunique()\n",
    "    value_of = general_data[col].unique()\n",
    "    if value == 1:\n",
    "        print(col)\n",
    "        print(value_of)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate alors que :\n",
    "\n",
    "- **EmployeeCount :** Cette colonne correspond à la présence ou non d'un employé dans l'entreprise dans les effectifs en 2015, on constate que chaque ligne du tableau est à 1 cela signifie donc que tous les employés présent dans les données était dans l'entreprise en 2015, il n'est donc pas intéressant de conserver cette donnée.\n",
    "<br>\n",
    "\n",
    "- **Over18 :** Cette colonne indique si l'age de l'employé est supérieure ou non à 18 ans, on constate que chaque ligne du tableau est à la valeure \"Y\" cela signifie donc que en 2015 chaque employé était majeur, il n'est donc pas intéressant de conserver cette donnée. \n",
    "<br>\n",
    "\n",
    "- **StandardHours :** Cette colonne spécifie le nombre d'heure inscrite sur le contrat de l'employé, chaque ligne étant positionnée à 8h on en déduit que tous les employés disposait du même type de contrat en 2015. Il n'est donc pas intéressant de conserver cette donnée.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Info:</b> Cette étude à également été effectuée sur les autres tables mais aucune valeur unique est apparue, nous conserverons alors toutes les données de celles-ci.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the non revelent columns\n",
    "general_dataset.drop(\"Over18\", axis=1, inplace=True)\n",
    "general_dataset.drop(\"EmployeeCount\", axis=1, inplace=True)\n",
    "general_dataset.drop(\"StandardHours\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Après avoir selectionné les données à conserver en fonction de différents facteurs voici une liste exhaustive de celles conservées pour la réalisation de notre modèle :\n",
    "\n",
    "###  <font color='green'> General_data </font>\n",
    "\n",
    "- **Attrition :** L'objet de notre étude, est-ce que l'employé a quitté l'entreprise durant l'année 2016 ?\n",
    "<br>\n",
    "\n",
    "- **BusinessTravel :** A quel fréquence l'employé a été amené à se déplacer dans le cadre de son travail en 2015 ? (Non-Travel = jamais, Travel_Rarely= rarement, Travel_Frequently = fréquemment)\n",
    "<br>\n",
    "\n",
    "- **DistanceFromHome :** Distance en km entre le logement de l'employé et l'entreprise.\n",
    "<br>\n",
    "\n",
    "- **Education : Niveau d'étude :** 1=Avant College (équivalent niveau Bac), 2=College (équivalent Bac+2), 3=Bachelor (Bac+3), 4=Master (Bac+5) et 5=PhD (Thèse de doctorat).\n",
    "<br>\n",
    "\n",
    "- **EducationField :** Domaine d'étude, matière principale\n",
    "<br>\n",
    "\n",
    "- **EmployeeId :** l'identifiant d'un employé\n",
    "<br>\n",
    "\n",
    "- **JobLevel :** Niveau hiérarchique dans l'entreprise de 1 à 5\n",
    "<br>\n",
    "\n",
    "- **JobRole :** Métier dans l'entreprise\n",
    "<br>\n",
    "\n",
    "- **MonthlyIncome :** Salaire brut en roupies par mois\n",
    "<br>\n",
    "\n",
    "- **NumCompaniesWorked :** Nombre d'entreprises pour lequel le salarié a travaillé avant de rejoindre HumanForYou.\n",
    "<br>\n",
    "\n",
    "- **PercentSalaryHike :** % d'augmentation du salaire en 2015.\n",
    "<br>\n",
    "\n",
    "- **StockOptionLevel :** Niveau d'investissement en actions de l'entreprise par le salarié.\n",
    "<br>\n",
    "\n",
    "- **TotalWorkingYears :** Nombre d'années d'expérience en entreprise du salarié pour le même type de poste.\n",
    "<br>\n",
    "\n",
    "- **TrainingTimesLastYear :** Nombre de jours de formation en 2015\n",
    "<br>\n",
    "\n",
    "- **YearsAtCompany :** Ancienneté dans l'entreprise\n",
    "<br>\n",
    "\n",
    "- **YearsSinceLastPromotion :** Nombre d'années depuis la dernière augmentation individuelle\n",
    "<br>\n",
    "\n",
    "- **YearsWithCurrentManager :** Nombre d'années de collaboration sous la responsabilité du manager actuel de l'employé.\n",
    "\n",
    "###  <font color='green'> Employee_survey_data </font>\n",
    "\n",
    "- **L'environnement de travail :** : noté 1 (\"Faible\"), 2 (\"Moyen\"), 3 (\"Élevé\") ou 4 (\"Très élevé\") : EnvironmentSatisfaction\n",
    "<br>\n",
    "\n",
    "- **Son travail :** noté de 1 à 4 comme précédemment : JobSatisfaction\n",
    "<br>\n",
    "\n",
    "- **Son équilibre entre vie professionnelle et vie privée :** noté 1 (\"Mauvais\"), 2 (\"Satisfaisant\"), 3 (\"Très satisfaisant\") ou 4 (\"Excellent\") : WorkLifeBalance\n",
    "\n",
    "###  <font color='green'> Manager_survey_data </font>\n",
    "\n",
    "- **Une évaluation de son implication dans son travail :** notée 1 ('Faible'), 2 (\"Moyenne\"), 3 (\"Importante\") ou 4 (\"Très importante\") : JobInvolvement\n",
    "<br>\n",
    "\n",
    "- **Une évaluation de son niveau de performance annuel pour l'entreprise :** notée 1 (\"Faible\"), 2 (\"Bon\"), 3 (\"Excellent\") ou 4 (\"Au delà des attentes\") : PerformanceRating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage binaire de l'attribut Attrition\n",
    "On convertit les données de l'attribut Attrition, les 'Yes' et 'No' deviennent respectivement des 1 et des 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_dataset['Attrition'] = general_dataset['Attrition'].map({'Yes': 1, 'No':0}) # convertir la colonne Attrition en 0 et 1\n",
    "\n",
    "fir_column = general_dataset.pop('Attrition') # retirer la colonne Attrition\n",
    "general_dataset.insert(0 ,'Attrition', fir_column) # la remettre en première colonne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "Nous allons créer des variables supplémentaires pour représenter chacun des catégories.\n",
    "**BusinessTravel**, **Department**, **EducationField**, **JobRole**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False) # sparse=False pour obtenir un tableau numpy (et non une matrice creuse)\n",
    "data_encoded = onehot_encoder.fit_transform(general_dataset[['BusinessTravel', 'Department', 'EducationField', 'JobRole']])\n",
    "onehot_encoder.categories_ # affiche les catégories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Echantillonage stratifié\n",
    "\n",
    "Nous désirons effectuer un échantillonage respectant les proportions de représentation des différentes catégories de salaire. bla bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_dataset[\"MonthlyIncome\"].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max à 200 000 on veux 10 cat donc /20 000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_dataset[\"MonthlyIncome_cat\"] = np.ceil(general_dataset[\"MonthlyIncome\"]/20000)\n",
    "\n",
    "general_dataset[\"MonthlyIncome_cat\"].hist(facecolor = '#ff0005', edgecolor='#000000', linewidth=0.8, bins=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "suppr la col d'origine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_dataset.drop(\"MonthlyIncome\", axis=1, inplace=True)\n",
    "general_dataset.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul temps de travail moyen + temps arrivé et temps départ moyen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nombreuses données sont manquantes parmis les horaires. Nous faisons le choix de supprimer une colonne contenant plus de 50% de données manquantes. Pour les autres données manquantes, nous les remplaçons par la date Unix qui correspond à une valeur nul en format date afin que ces données n'aient pas d'influence sur nos calculs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare time dataset\n",
    "def dropNan(dataset):\n",
    "\n",
    "    data = dataset.copy()\n",
    "    colNames = [col for col in data.columns]\n",
    "\n",
    "    percent= [round(100-((data[col].count()/len(data.index))*100),2) for col in data.columns]\n",
    "    indexes = [index for index, value in enumerate(percent) if value > 50]\n",
    "\n",
    "    for i in indexes:\n",
    "        data.drop(colNames[i], axis=1, inplace=True)\n",
    "        \n",
    "    data.fillna(\"1970-01-01 00:00:00\", inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inTime_prep = dropNan(in_time)\n",
    "outTime_prep = dropNan(out_time)\n",
    "inTime_prep.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec(date):\n",
    "    getlast = ((str(date))[-8:]).replace(\":\", \"\")\n",
    "    time = (int(getlast[4:6])) + ((int(getlast[2:4])) * 60) + (int(getlast[0:2])) * 3600\n",
    "    return time\n",
    "\n",
    "def average_In_Out_Time(time):\n",
    "    tabs = []\n",
    "    for row in range(0, len(time)):\n",
    "        means = [sec(dt.datetime.strptime(time.iloc[row, col], \"%Y-%m-%d %H:%M:%S\")) for col in range(1, len(time.columns))]\n",
    "        means_convert = round(((int((round(mean(means), 0)))) / 3600),2)\n",
    "        tabs += [means_convert]\n",
    "    return tabs\n",
    "    \n",
    "def average_worktime(out_time, in_time) :\n",
    "    tab = []\n",
    "    for lines in range(0, len(out_time)):\n",
    "        worktime = [(((dt.datetime.strptime(out_time.iloc[lines,col], \"%Y-%m-%d %H:%M:%S\")) - (dt.datetime.strptime(in_time.iloc[lines,col], \"%Y-%m-%d %H:%M:%S\"))).total_seconds()) for col in range(1, len(out_time.columns))]\n",
    "        worktime_convert = round(((int((round(mean(worktime), 0)))) / 3600),2)\n",
    "        tab += [worktime_convert]\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'EmployeeID': inTime_prep.iloc[:, 0], 'Average_Worktime': average_worktime(outTime_prep, inTime_prep), 'Average_In_Time': average_In_Out_Time(inTime_prep), 'Average_Out_Time': average_In_Out_Time(outTime_prep)}\n",
    "wortime_employee = pd.DataFrame(data=d)\n",
    "wortime_employee.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion des tables\n",
    "Nous allons fusionner les dataframes selon l'id de l'employé pour inclure les evaluations d'impliquation, les évaluations de niveaux de performance et les données concernant les horaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the dataframes\n",
    "survey_dataset = pd.merge(employee_survey_data, manager_survey_data, on='EmployeeID')\n",
    "dataset_with_survey = pd.merge(general_dataset, survey_dataset, on='EmployeeID')\n",
    "Dataset = pd.merge(dataset_with_survey, wortime_employee, on='EmployeeID')\n",
    "Dataset.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nettoyage des données\n",
    "\n",
    "Nous allons supprimer les valeurs manquantes.\n",
    "Nous constatons qu'il y a des valeurs manquantes pour 110 employés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_incomplete_rows = Dataset[Dataset.isnull().any(axis=1)]\n",
    "len(sample_incomplete_rows.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela correspond à moins de 3% de nos valeurs.\n",
    "\n",
    "Nous faisons donc le choix de supprimer les lignes contenant des valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(sample_incomplete_rows.index)/len(Dataset.index))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.dropna(inplace=True)\n",
    "Dataset.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmatrix = Dataset.corr()\n",
    "corrmatrix['Attrition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\"Attrition\", \"Average_Worktime\", \"Average_Out_Time\", \"YearsWithCurrManager\", \"YearsAtCompany\", \"TotalWorkingYears\"]\n",
    "scat_matrix = scatter_matrix(Dataset[attributes], figsize=(15, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.plot(kind=\"scatter\", x=\"Attrition\", y=\"Average_Worktime\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline de transformation test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class EthicColumnsRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy.drop(\"Age\", axis=1, inplace=True) \n",
    "        X_copy.drop(\"Gender\", axis=1, inplace=True)\n",
    "        X_copy.drop(\"MaritalStatus\", axis=1, inplace=True)\n",
    "        X_copy.drop(\"Over18\", axis=1, inplace=True)\n",
    "        X_copy.drop(\"EmployeeCount\", axis=1, inplace=True)\n",
    "        X_copy.drop(\"StandardHours\", axis=1, inplace=True)\n",
    "        return X_copy.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataset_pipeline = Pipeline([\n",
    "    ('removeEthicColumns', EthicColumnsRemover()),\n",
    "    ('onehot_encoder', OneHotEncoder(sparse=False)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "transformed_data = dataset_pipeline.fit_transform(general_data)\n",
    "transformed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
